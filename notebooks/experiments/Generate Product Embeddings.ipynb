{"cells":[{"cell_type":"markdown","source":["## Import Libraries and Load Data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c0548a6d-ce75-4d92-bff1-2ac4b59cf446","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["%pip install mlflow"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"099c794b-1a3e-47f9-8e11-c6cff7c50a3a","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Python interpreter will be restarted.\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (2.1.1)\nRequirement already satisfied: gunicorn<21 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (20.1.0)\nRequirement already satisfied: docker<7,>=4.0.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (6.0.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (6.0)\nRequirement already satisfied: pandas<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.3.4)\nRequirement already satisfied: shap<1,>=0.40 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (0.41.0)\nRequirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (5.2.0)\nRequirement already satisfied: gitpython<4,>=2.1.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (3.1.31)\nRequirement already satisfied: cloudpickle<3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (4.21.5)\nRequirement already satisfied: pytz<2023 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2021.3)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.20.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2.26.0)\nRequirement already satisfied: sqlalchemy<2,>=1.4.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (1.4.46)\nRequirement already satisfied: alembic<2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (1.9.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.7.1)\nRequirement already satisfied: Flask<3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (2.2.3)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (0.24.2)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (0.3)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (3.4.1)\nRequirement already satisfied: querystring-parser<2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: pyarrow<11,>=4.0.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: packaging<23 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (21.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (0.4.3)\nRequirement already satisfied: databricks-cli<1,>=0.8.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (0.17.4)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (8.0.3)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from alembic<2->mlflow) (1.2.4)\nRequirement already satisfied: tabulate>=0.7.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\nRequirement already satisfied: six>=1.10.0 in /databricks/python3/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\nRequirement already satisfied: pyjwt>=1.7.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.6.0)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.26.7)\nRequirement already satisfied: websocket-client>=0.32.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\nRequirement already satisfied: itsdangerous>=2.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from Flask<3->mlflow) (2.1.2)\nRequirement already satisfied: Werkzeug>=2.2.2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from Flask<3->mlflow) (2.2.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\nRequirement already satisfied: smmap<6,>=3.0.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\nRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.9/dist-packages (from gunicorn<21->mlflow) (58.0.4)\nRequirement already satisfied: zipp>=0.5 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow) (3.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.0.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.10.0)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (8.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.2)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2021.10.8)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.0.1)\nRequirement already satisfied: numba in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from shap<1,>=0.40->mlflow) (0.56.4)\nRequirement already satisfied: tqdm>4.25.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from shap<1,>=0.40->mlflow) (4.64.1)\nRequirement already satisfied: slicer==0.0.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from shap<1,>=0.40->mlflow) (0.0.7)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sqlalchemy<2,>=1.4.0->mlflow) (2.0.2)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from numba->shap<1,>=0.40->mlflow) (0.39.1)\nPython interpreter will be restarted.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Python interpreter will be restarted.\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (2.1.1)\nRequirement already satisfied: gunicorn<21 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (20.1.0)\nRequirement already satisfied: docker<7,>=4.0.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (6.0.1)\nRequirement already satisfied: pyyaml<7,>=5.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (6.0)\nRequirement already satisfied: pandas<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.3.4)\nRequirement already satisfied: shap<1,>=0.40 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (0.41.0)\nRequirement already satisfied: importlib-metadata!=4.7.0,<6,>=3.7.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (5.2.0)\nRequirement already satisfied: gitpython<4,>=2.1.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (3.1.31)\nRequirement already satisfied: cloudpickle<3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (2.2.1)\nRequirement already satisfied: protobuf<5,>=3.12.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (4.21.5)\nRequirement already satisfied: pytz<2023 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2021.3)\nRequirement already satisfied: numpy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.20.3)\nRequirement already satisfied: requests<3,>=2.17.3 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (2.26.0)\nRequirement already satisfied: sqlalchemy<2,>=1.4.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (1.4.46)\nRequirement already satisfied: alembic<2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (1.9.4)\nRequirement already satisfied: Jinja2<4,>=2.11 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (3.1.2)\nRequirement already satisfied: scipy<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (1.7.1)\nRequirement already satisfied: Flask<3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (2.2.3)\nRequirement already satisfied: matplotlib<4 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (3.4.3)\nRequirement already satisfied: scikit-learn<2 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (0.24.2)\nRequirement already satisfied: entrypoints<1 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (0.3)\nRequirement already satisfied: markdown<4,>=3.3 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (3.4.1)\nRequirement already satisfied: querystring-parser<2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: pyarrow<11,>=4.0.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (7.0.0)\nRequirement already satisfied: packaging<23 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (21.0)\nRequirement already satisfied: sqlparse<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (0.4.3)\nRequirement already satisfied: databricks-cli<1,>=0.8.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from mlflow) (0.17.4)\nRequirement already satisfied: click<9,>=7.0 in /databricks/python3/lib/python3.9/site-packages (from mlflow) (8.0.3)\nRequirement already satisfied: Mako in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from alembic<2->mlflow) (1.2.4)\nRequirement already satisfied: tabulate>=0.7.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\nRequirement already satisfied: six>=1.10.0 in /databricks/python3/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\nRequirement already satisfied: oauthlib>=3.1.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\nRequirement already satisfied: pyjwt>=1.7.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.6.0)\nRequirement already satisfied: urllib3>=1.26.0 in /databricks/python3/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.26.7)\nRequirement already satisfied: websocket-client>=0.32.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from docker<7,>=4.0.0->mlflow) (1.5.1)\nRequirement already satisfied: itsdangerous>=2.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from Flask<3->mlflow) (2.1.2)\nRequirement already satisfied: Werkzeug>=2.2.2 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from Flask<3->mlflow) (2.2.3)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from gitpython<4,>=2.1.0->mlflow) (4.0.10)\nRequirement already satisfied: smmap<6,>=3.0.1 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow) (5.0.0)\nRequirement already satisfied: setuptools>=3.0 in /usr/local/lib/python3.9/dist-packages (from gunicorn<21->mlflow) (58.0.4)\nRequirement already satisfied: zipp>=0.5 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from importlib-metadata!=4.7.0,<6,>=3.7.0->mlflow) (3.14.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from Jinja2<4,>=2.11->mlflow) (2.1.2)\nRequirement already satisfied: python-dateutil>=2.7 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (1.3.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (3.0.4)\nRequirement already satisfied: cycler>=0.10 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (0.10.0)\nRequirement already satisfied: pillow>=6.2.0 in /databricks/python3/lib/python3.9/site-packages (from matplotlib<4->mlflow) (8.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (3.2)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.9/site-packages (from requests<3,>=2.17.3->mlflow) (2021.10.8)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (2.2.0)\nRequirement already satisfied: joblib>=0.11 in /databricks/python3/lib/python3.9/site-packages (from scikit-learn<2->mlflow) (1.0.1)\nRequirement already satisfied: numba in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from shap<1,>=0.40->mlflow) (0.56.4)\nRequirement already satisfied: tqdm>4.25.0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from shap<1,>=0.40->mlflow) (4.64.1)\nRequirement already satisfied: slicer==0.0.7 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from shap<1,>=0.40->mlflow) (0.0.7)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from sqlalchemy<2,>=1.4.0->mlflow) (2.0.2)\nRequirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /local_disk0/.ephemeral_nfs/cluster_libraries/python/lib/python3.9/site-packages (from numba->shap<1,>=0.40->mlflow) (0.39.1)\nPython interpreter will be restarted.\n"]}}],"execution_count":0},{"cell_type":"code","source":["import pandas as pd\nimport numpy as np\nimport random\nimport pickle\n\nimport re\nimport os, sys\nimport jieba\nimport jieba.posseg as pseg\nimport logging \n\nfrom sys import version_info\nfrom tqdm import tqdm\n\nimport gensim\nfrom gensim.models import Word2Vec \nimport umap\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport warnings;\nwarnings.filterwarnings('ignore')\n\nimport mlflow\nimport mlflow.pyfunc\nfrom mlflow.models.signature import infer_signature\n\nimport os\nimport sys\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\nimport cloudpickle"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"81e6c7c9-a047-411e-bbf2-16a0cfa05092","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"},"removedWidgets":[],"addedWidgets":{},"executionCount":null,"metadata":{"kernelSessionId":"f2589a3f-d4382fd583fe0cc0a0b9a01d"},"type":"mimeBundle","arguments":{}}},"output_type":"display_data","data":{"text/plain":"","application/vnd.databricks.v1+bamboolib_hint":"{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}"}}],"execution_count":0},{"cell_type":"code","source":["%sql\nREFRESH TABLE invoices;\nREFRESH TABLE stopwords_en;"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"implicitDf":true},"nuid":"02f3d87e-4cc1-49fa-9675-f3f8f1e304b9","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr></tr></thead><tbody></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"code","source":["invoices = spark.sql(\"SELECT * FROM invoices\")\ndf = invoices.toPandas()\ndf.head()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d6a42c49-b7ce-41e9-8d97-aa6885ae4869","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>InvoiceNo</th>\n      <th>StockCode</th>\n      <th>Description</th>\n      <th>Quantity</th>\n      <th>InvoiceDate</th>\n      <th>UnitPrice</th>\n      <th>CustomerID</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>536365</td>\n      <td>85123A</td>\n      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>2.55</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>536365</td>\n      <td>71053</td>\n      <td>WHITE METAL LANTERN</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>536365</td>\n      <td>84406B</td>\n      <td>CREAM CUPID HEARTS COAT HANGER</td>\n      <td>8</td>\n      <td>12/1/10 8:26</td>\n      <td>2.75</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>536365</td>\n      <td>84029G</td>\n      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>536365</td>\n      <td>84029E</td>\n      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n  </tbody>\n</table>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>InvoiceNo</th>\n      <th>StockCode</th>\n      <th>Description</th>\n      <th>Quantity</th>\n      <th>InvoiceDate</th>\n      <th>UnitPrice</th>\n      <th>CustomerID</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>536365</td>\n      <td>85123A</td>\n      <td>WHITE HANGING HEART T-LIGHT HOLDER</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>2.55</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>536365</td>\n      <td>71053</td>\n      <td>WHITE METAL LANTERN</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>536365</td>\n      <td>84406B</td>\n      <td>CREAM CUPID HEARTS COAT HANGER</td>\n      <td>8</td>\n      <td>12/1/10 8:26</td>\n      <td>2.75</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>536365</td>\n      <td>84029G</td>\n      <td>KNITTED UNION FLAG HOT WATER BOTTLE</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>536365</td>\n      <td>84029E</td>\n      <td>RED WOOLLY HOTTIE WHITE HEART.</td>\n      <td>6</td>\n      <td>12/1/10 8:26</td>\n      <td>3.39</td>\n      <td>17850</td>\n      <td>United Kingdom</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's take a quick look at our data. You can __download it from [here](https://archive.ics.uci.edu/ml/machine-learning-databases/00352/).__"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3e9e414d-0b3a-439f-bd0b-c78963e0c8a0","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Given below is the description of the fields in this dataset:\n\n1. __InvoiceNo:__ Invoice number, a unique number assigned to each transaction.\n\n2. __StockCode:__ Product/item code. a unique number assigned to each distinct product.\n\n3. __Description:__ Product description\n\n4. __Quantity:__ The quantities of each product per transaction.\n\n5. __InvoiceDate:__ Invoice Date and time. The day and time when each transaction was generated.\n\n6. __CustomerID:__ Customer number, a unique number assigned to each customer."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a0ff8336-33ad-4179-a960-7524154c230f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e4a533e-17e0-45f4-9d74-0600f71c0125","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[4]: (65499, 8)","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[4]: (65499, 8)"]}}],"execution_count":0},{"cell_type":"markdown","source":["The dataset contains 541,909 transactions. That is a pretty good number for us."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e9093a66-f752-4302-b580-c8522a11af35","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Treat Missing Data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cd629d0f-7c2a-491e-ac7d-8b6a76b75f83","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# check for missing values\ndf.isnull().sum()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d85d31af-54aa-46ba-8142-58d95129737e","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[5]: InvoiceNo          0\nStockCode          0\nDescription      166\nQuantity           0\nInvoiceDate        0\nUnitPrice          0\nCustomerID     25281\nCountry            0\ndtype: int64","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[5]: InvoiceNo          0\nStockCode          0\nDescription      166\nQuantity           0\nInvoiceDate        0\nUnitPrice          0\nCustomerID     25281\nCountry            0\ndtype: int64"]}}],"execution_count":0},{"cell_type":"markdown","source":["<br>\nSince we have sufficient data, we will drop all the rows with missing values."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c7529167-7131-4854-a8f6-6604240f4716","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# remove missing values\ndf.dropna(inplace=True)\n\n# again check missing values\ndf.isnull().sum()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4b74f6c8-bc0b-456f-9bb9-e4e117d5c776","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[6]: InvoiceNo      0\nStockCode      0\nDescription    0\nQuantity       0\nInvoiceDate    0\nUnitPrice      0\nCustomerID     0\nCountry        0\ndtype: int64","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[6]: InvoiceNo      0\nStockCode      0\nDescription    0\nQuantity       0\nInvoiceDate    0\nUnitPrice      0\nCustomerID     0\nCountry        0\ndtype: int64"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Data Preparation"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b2ae39c2-7231-42b1-be2b-b8811aff88cb","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Let's convert the StockCode to string datatype."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"90e08e42-e77f-4cd4-953d-32f6d36b6b15","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["df['StockCode']= df['StockCode'].astype(str)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"97a21641-9cc2-4f06-9e3b-b0122479ce4c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["Let's check out the number of unique customers in our dataset."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"244faca6-836f-4748-a13c-56c258af087c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["products = df[[\"StockCode\", \"Description\"]]\n\n# remove duplicates\nproducts.drop_duplicates(inplace=True, subset='StockCode', keep=\"last\")\n\n# create product-ID and product-description dictionary\nproducts_dict = products.groupby('StockCode')['Description'].apply(list).to_dict()\n\nprint(products)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ca6dd27f-11a7-4309-9f1c-7e1a474e59f2","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"      StockCode                         Description\n107       84854                 GIRLY PINK TOOL SET\n201      35004G          SET OF 3 GOLD FLYING DUCKS\n336       20820               SILVER LOOKING MIRROR\n496      90129F          RED GLASS TASSLE BAG CHARM\n525      90199C     5 STRAND GLASS NECKLACE CRYSTAL\n...         ...                                 ...\n65097     22636  CHILDS BREAKFAST SET CIRCUS PARADE\n65098     84945  MULTI COLOUR SILVER T-LIGHT HOLDER\n65099     22440       BALLOON WATER BOMB PACK OF 35\n65100     22437       SET OF 9 BLACK SKULL BALLOONS\n65101     22423            REGENCY CAKESTAND 3 TIER\n\n[2589 rows x 2 columns]\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["      StockCode                         Description\n107       84854                 GIRLY PINK TOOL SET\n201      35004G          SET OF 3 GOLD FLYING DUCKS\n336       20820               SILVER LOOKING MIRROR\n496      90129F          RED GLASS TASSLE BAG CHARM\n525      90199C     5 STRAND GLASS NECKLACE CRYSTAL\n...         ...                                 ...\n65097     22636  CHILDS BREAKFAST SET CIRCUS PARADE\n65098     84945  MULTI COLOUR SILVER T-LIGHT HOLDER\n65099     22440       BALLOON WATER BOMB PACK OF 35\n65100     22437       SET OF 9 BLACK SKULL BALLOONS\n65101     22423            REGENCY CAKESTAND 3 TIER\n\n[2589 rows x 2 columns]\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["There are 4,372 customers in our dataset. For each of these customers we will extract their buying history. In other words, we can have 4,372 sequences of purchases."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"424b1fef-88e7-4c42-b140-8f08da8722d3","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["It is a good practice to set aside a small part of the dataset for validation purpose. Therefore, I will use data of 90% of the customers to create word2vec embeddings. Let's split the data."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a217fb14-c48f-4e74-b4cd-b3ae18f7e597","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n\ntrain_df, validation_df = train_test_split(products, test_size=0.2)\ntrain_df"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"23e68a59-b66f-4939-9d4f-51ab77d85c14","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StockCode</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64162</th>\n      <td>22852</td>\n      <td>DOG BOWL VINTAGE CREAM</td>\n    </tr>\n    <tr>\n      <th>50198</th>\n      <td>37444C</td>\n      <td>PINK BREAKFAST CUP AND SAUCER</td>\n    </tr>\n    <tr>\n      <th>46810</th>\n      <td>21815</td>\n      <td>STAR  T-LIGHT HOLDER</td>\n    </tr>\n    <tr>\n      <th>52604</th>\n      <td>21468</td>\n      <td>BUTTERFLY CROCHET FOOD COVER</td>\n    </tr>\n    <tr>\n      <th>28737</th>\n      <td>84313C</td>\n      <td>ORANGE TV TRAY TABLE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38303</th>\n      <td>90019A</td>\n      <td>SILVER M.O.P ORBIT BRACELET</td>\n    </tr>\n    <tr>\n      <th>64254</th>\n      <td>22227</td>\n      <td>HANGING HEART MIRROR DECORATION</td>\n    </tr>\n    <tr>\n      <th>64736</th>\n      <td>22844</td>\n      <td>VINTAGE CREAM DOG FOOD CONTAINER</td>\n    </tr>\n    <tr>\n      <th>64987</th>\n      <td>22963</td>\n      <td>JAM JAR WITH GREEN LID</td>\n    </tr>\n    <tr>\n      <th>64277</th>\n      <td>22808</td>\n      <td>SET OF 6 T-LIGHTS EASTER CHICKS</td>\n    </tr>\n  </tbody>\n</table>\n<p>2071 rows × 2 columns</p>\n</div>","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>StockCode</th>\n      <th>Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>64162</th>\n      <td>22852</td>\n      <td>DOG BOWL VINTAGE CREAM</td>\n    </tr>\n    <tr>\n      <th>50198</th>\n      <td>37444C</td>\n      <td>PINK BREAKFAST CUP AND SAUCER</td>\n    </tr>\n    <tr>\n      <th>46810</th>\n      <td>21815</td>\n      <td>STAR  T-LIGHT HOLDER</td>\n    </tr>\n    <tr>\n      <th>52604</th>\n      <td>21468</td>\n      <td>BUTTERFLY CROCHET FOOD COVER</td>\n    </tr>\n    <tr>\n      <th>28737</th>\n      <td>84313C</td>\n      <td>ORANGE TV TRAY TABLE</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>38303</th>\n      <td>90019A</td>\n      <td>SILVER M.O.P ORBIT BRACELET</td>\n    </tr>\n    <tr>\n      <th>64254</th>\n      <td>22227</td>\n      <td>HANGING HEART MIRROR DECORATION</td>\n    </tr>\n    <tr>\n      <th>64736</th>\n      <td>22844</td>\n      <td>VINTAGE CREAM DOG FOOD CONTAINER</td>\n    </tr>\n    <tr>\n      <th>64987</th>\n      <td>22963</td>\n      <td>JAM JAR WITH GREEN LID</td>\n    </tr>\n    <tr>\n      <th>64277</th>\n      <td>22808</td>\n      <td>SET OF 6 T-LIGHTS EASTER CHICKS</td>\n    </tr>\n  </tbody>\n</table>\n<p>2071 rows × 2 columns</p>\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's create sequences of purchases made by the customers in the dataset for both the train and validation set."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2d9343bf-dc80-4f6c-a95f-f2e53956eeab","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["class Preprocess():\n    def __init__(self, lang=\"en\", filter_words=[], stopwords_path='', userdict_path='', filter_pos=[]):\n        '''\n        Input:\n            filter_words: list of strings. Words need to be filtered after tokenization.\n            stopwords_path: string. Path of stopwords file.  \n            userdict_path: string. Path of userdict file.\n            filter_pos: list of POS strings. POS need to be filtered during tokenization.\n        '''\n        #if stopwords_path=='':\n        #    stopwords_path = \"textgo/textgo/data/stopwords_en.txt\"\n        self.stopwords = spark.sql(\"SELECT stopword FROM stopwords_en\").toPandas()[\"stopword\"].values.tolist()       \n        #self.stopwords = open(stopwords_path).read().strip().split('\\n')\n        self.stopwords.extend(filter_words) \n        self.stopwords.append(' ')\n        if sys.version_info[0] == 2: # python2\n            self.stopwords = [word.decode('utf-8') for word in self.stopwords] # for python2\n        self.stopwords = set(self.stopwords)\n        self.filter_pos_num = len(filter_pos)\n        self.filter_pos = set(filter_pos)\n\n    def clean(self, texts, drop_space=False):\n        '''Clean text, including dropping html tags, url, extra space and punctuation \n        as well as string lower.\n        Input:\n            text: list of strings.\n        Output:\n            text: preprocessed string.\n        '''\n        ptexts = []\n        for text in texts:\n            # drop \\n\n            text = re.sub('\\n','',text)\n            # drop html tags \n            text = re.sub('<[^>]*>|&quot|&nbsp','',text)\n            # drop url\n            url_regrex = u'((http|https)\\\\:\\\\/\\\\/)?[a-zA-Z0-9\\\\.\\\\/\\\\?\\\\:@\\\\-_=#]+\\\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\\\.\\\\&\\\\/\\\\?\\\\:@\\\\-_=#])*'\n            text = re.sub(url_regrex,'',text)\n            # only keep Chinese/English/space/numbers/decimal\n            text = re.sub(u\"[^\\u4E00-\\u9FFF^a-z^A-Z^\\s^0-9^\\d+(\\.\\d+)?]\", \" \",text) \n            if drop_space:\n                # drop any space\n                text = re.sub(u\"[\\s]{1,}\",\"\",text).strip()\n            else:\n                # drop space at the start and in the end\n                text = re.sub(u\"\\s$|^\\s\",\"\",text)\n                # replace more than 2 space with 1 space\n                text = re.sub(u\"[\\s]{2,}\",\" \",text).strip()\n            # lower string\n            text = text.lower()\n            ptexts.append(text)\n        return ptexts\n\n    def tokenize(self, texts, drop_stopwords=True):\n        '''Tokenize string.\n        Input:\n            text: list of strings.\n            drop_stopwords: boolean. Whether drop stopwords or not.\n        Output:\n            tokens_list: list of list of tokens.\n        '''\n        tokens_list = []\n        for text in texts:\n            tokens = text.split(' ')\n            if drop_stopwords:\n                tokens = [token for token in tokens if token not in self.stopwords]\n            tokens_list.append(tokens)\n        return tokens_list\n\n    def preprocess(self, texts, sep=' ', drop_stopwords=True):\n        '''Text preprocess for English/Chinese, including clean text, tokenize and remove \n        stopwords.\n        Input:\n            texts: list of text strings\n            sep: string used to join words after tokenization\n            drop_stopwords: boolean. Whether drop stopwords or not.\n        Output:\n            list of preprocessed text strings (tokens join by sep)\n        '''\n        # clean text\n        ptexts = self.clean(texts)\n        # tokenize\n        tokens_list = self.tokenize(ptexts, drop_stopwords)\n        # join by sep\n        result = [sep.join(tokens) for tokens in tokens_list]\n        return tokens_list"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"0a7dc20d-f1cd-49d7-b39a-95d84b458df2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["preprocess = Preprocess()\npreprocessed_data = preprocess.preprocess(train_df[\"Description\"].to_list())\npreprocessed_data[:3]"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f053f88a-e4b2-48fc-b53e-c5bd589f8574","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[11]: [['dog', 'bowl', 'vintage', 'cream'],\n ['pink', 'breakfast', 'cup', 'saucer'],\n ['star', 'light', 'holder']]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[11]: [['dog', 'bowl', 'vintage', 'cream'],\n ['pink', 'breakfast', 'cup', 'saucer'],\n ['star', 'light', 'holder']]"]}}],"execution_count":0},{"cell_type":"code","source":["train_df.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e2c21d83-3bcc-40cc-afd8-e35e41f2f159","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"Out[12]: (2071, 2)","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[12]: (2071, 2)"]}}],"execution_count":0},{"cell_type":"markdown","source":["## Build word2vec Embeddings for Products"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ae66e05d-d565-47e3-9c13-bb52be1a5043","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["PYTHON_VERSION = \"{major}.{minor}.{micro}\".format(major=version_info.major,\n                                                  minor=version_info.minor,\n                                                  micro=version_info.micro)\n\nconda_env = {\n    'channels': ['defaults'],\n    'dependencies': [\n      'python={}'.format(PYTHON_VERSION),\n      'pip',\n      {\n        'pip': [\n          'mlflow',\n          'gensim=={}'.format(gensim.__version__),\n          'cloudpickle=={}'.format(cloudpickle.__version__),\n        ],\n      },\n    ],\n    'name': 'gensim_env'\n}\n\nclass GensimModelWrapper(mlflow.pyfunc.PythonModel):\n    def __init__(self, model):\n        self.model = model\n    \n    def load_context(self, context):\n        '''Load embedding model including word2vec.\n        Input: \n            context: string. Path of model.\n        Output:\n            model: model object.\n        '''\n        #self.model = Word2Vec.load(context.artifacts[\"gensim_model\"])\n        self.model = KeyedVectors.load(context.artifacts[\"gensim_model\"], mmap='r').wv\n        \n    def predict(self, model, data):\n        return self.word2vec(data)\n\n    def word2vec(self, corpus):\n        '''Get Word2Vec embeddings.   \n        Input:    \n            corpus: list of preprocessed strings.   \n        Output:    \n            embeddings: array of shape [n_sample, dim]    \n        '''\n        embeddings = [] \n        # drop tokens which not in vocab\n        for text in corpus:\n            print(text)\n            tokens = text.split(' ')\n            tokens = [token for token in tokens if token in self.model.vocab]\n            #logger.info(', '.join(tokens))\n            print(tokens)\n            if len(tokens)==0:\n                embedding = self.model['unk'].tolist()\n            else:\n                embedding = np.mean(self.model[tokens],axis=0).tolist()\n            embeddings.append(embedding)\n            print(embedding)\n        embeddings = np.array(embeddings)\n        return embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21d904ae-e0d0-46a4-ab60-4dad3ef8f345","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["mlflow.end_run()\n\nmlflow.set_experiment(\"/Shared/embedding\")\n\nmlflow.start_run()\n\n# Hyperparameters\nwindow=10\nsg=1\nhs=0\nnegative=10\nalpha=0.03\nmin_alpha=0.0007\nseed=14\nepochs=10\n\n# train word2vec model\nmodel = Word2Vec(\n    window = window, \n    sg = sg, \n    hs = hs,\n    negative = negative, # for negative sampling\n    alpha=alpha, \n    min_alpha=min_alpha,\n    seed = seed\n)\n\nmlflow.log_param('window', window)\nmlflow.log_param('sg', sg)\nmlflow.log_param('hs', hs)\nmlflow.log_param('negative', negative)\nmlflow.log_param('alpha', alpha)\nmlflow.log_param('min_alpha', min_alpha)\nmlflow.log_param('seed', seed)\nmlflow.log_param('epochs', epochs)\n\nmodel.build_vocab(preprocessed_data, progress_per=200)\n\nmodel.train(\n    preprocessed_data, \n    total_examples = model.corpus_count, \n    epochs=epochs, \n    report_delay=1\n)\n\nwrappedModel = GensimModelWrapper(model)\n\n#signature = infer_signature(preprocessed_data, wrappedModel.predict(None, preprocessed_data))\nmlflow.pyfunc.log_model(\"lattest_gensim_model\", python_model=wrappedModel, conda_env=conda_env)\n\nmlflow.end_run()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2e4bcd47-fb7a-483d-bc95-a51486dfc602","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"name":null,"datasetInfos":[],"data":"2023/02/20 11:09:45 INFO mlflow.tracking.fluent: Experiment with name '/Shared/embedding' does not exist. Creating a new experiment.\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["2023/02/20 11:09:45 INFO mlflow.tracking.fluent: Experiment with name '/Shared/embedding' does not exist. Creating a new experiment.\n"]}}],"execution_count":0},{"cell_type":"code","source":["# save word2vec model\nmodel.save(\"word2vec_2.model\")\n\nmlflow_pyfunc_model_path = \"gensim_mlflow_pyfunc_custom\"\nmlflow.pyfunc.save_model(path=mlflow_pyfunc_model_path, python_model=GensimWrapper(), conda_env=conda_env, artifacts=artifacts)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f7965a9b-9587-4877-9232-81fa30a3fe00","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["# Load and test gensim model\nartifacts = {\n    \"gensim_model\": \"word2vec.model\"\n}\n\nloaded_model = mlflow.pyfunc.load_model(artifacts)\n\ninput_data = ['jumbo bag', \"bag\"]\n# Evaluate the model\ntest_predictions = loaded_model.predict(input_data)\nprint(test_predictions)\n\nMetrics().cosine_sim(test_predictions[0], test_predictions[1])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d24531a-c654-493f-84c7-3c177625c1fe","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["As we do not plan to train the model any further, we are calling init_sims(), which will make the model much more memory-efficient."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"a0680e3e-41ce-461a-8599-7bd6d631f4af","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["model.init_sims(replace=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"3e3e4bc0-9134-403d-9887-3cb63601175f","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["print(model)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"90634054-1f78-4fa0-8237-c139c27f1044","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Now we will extract the vectors of all the words in our vocabulary and store it in one place for easy access."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4ac8c123-cd6f-4817-9f82-66c20123aa11","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# extract all vectors\nX = model[model.wv.vocab]\n\nX.shape"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c25d5ea6-c033-4432-88ca-93f2bf942af0","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["%sql CREATE DATABASE IF NOT EXISTS feature_store_embeddings;\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"implicitDf":true},"nuid":"e5e1e6c4-010a-42cc-9f16-f32d4537bc67","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["fs = feature_store.FeatureStoreClient()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"828f425e-5399-434d-bf2e-d68f740e1cba","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"bbfe8fbc-1dce-4786-83f1-6d3a9791b1d5","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Visualize word2vec Embeddings"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5ea622cd-220e-4d2c-9554-58d3968d7e7f","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["It is always quite helpful to visualize the embeddings that you have created. Over here we have 100 dimensional embeddings. We can't even visualize 4 dimensions let alone 100. Therefore, we are going to reduce the dimensions of the product embeddings from 100 to 2 by using the UMAP algorithm, it is used for dimensionality reduction."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"21053716-ccca-4961-a8fc-f155d2c646aa","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["cluster_embedding = umap.UMAP(n_neighbors=30, min_dist=0.0,\n                              n_components=2, random_state=42).fit_transform(X)\n\nplt.figure(figsize=(10,9))\nplt.scatter(cluster_embedding[:, 0], cluster_embedding[:, 1], s=3, cmap='Spectral')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"44da8505-4995-434c-a60a-4b9e55467749","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Every dot in this plot is a product. As you can see, there are several tiny clusters of these datapoints. These are groups of similar products."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9a8d11c3-62b0-47c9-9cae-d3c78a8674e8","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["## Start Recommending Products"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4db88f2e-1939-4328-92e7-54ea9ff61782","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Congratulations! We are finally ready with the word2vec embeddings for every product in our online retail dataset. Now our next step is to suggest similar products for a certain product or a product's vector."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa24e666-46ce-4af8-875f-935adf793276","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Let's first create a product-ID and product-description dictionary to easily map a product's description to its ID and vice versa."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b0566fd7-8276-432a-8516-8ff404e77df9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["products = train_df[[\"StockCode\", \"Description\"]]\n\n# remove duplicates\nproducts.drop_duplicates(inplace=True, subset='StockCode', keep=\"last\")\n\n# create product-ID and product-description dictionary\nproducts_dict = products.groupby('StockCode')['Description'].apply(list).to_dict()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"7f987bd1-ccf3-438b-b69c-ae8431daad01","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"code","source":["# test the dictionary\nproducts_dict['84029E']"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ded93737-c823-4be6-a3f2-60b89cc40d36","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["<br>\n\nI have defined the function below. It will take a product's vector (n) as input and return top 6 similar products."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"47a9a490-0f47-438a-b825-0b786c6f4648","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def similar_products(v, n = 6):\n    \n    # extract most similar products for the input vector\n    ms = model.similar_by_vector(v, topn= n+1)[1:]\n    \n    # extract name and similarity score of the similar products\n    new_ms = []\n    for j in ms:\n        pair = (products_dict[j[0]][0], j[1])\n        new_ms.append(pair)\n        \n    return new_ms        "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"670b1a9d-7d5c-47b2-a83a-36b0f32e5356","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Let's try out our function by passing the vector of the product '90019A' ('SILVER M.O.P ORBIT BRACELET')"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b023dbb0-7066-4abe-9cb2-b77c2d0b4795","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["similar_products(model['84029E'])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"eec6474d-9fb1-48ae-ba5d-78dbe03f7b46","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["<br>\n\nCool! The results are pretty relevant and match well with the input product. However, this output is based on the vector of a single product only. What if we want recommend a user products based on the multiple purchases he or she has made in the past?\n\nOne simple solution is to take average of all the vectors of the products he has bought so far and use this resultant vector to find similar products. For that we will use the function below that takes in a list of product ID's and gives out a 100 dimensional vector which is mean of vectors of the products in the input list."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c530b872-67c2-4003-baec-9faa91c75ee9","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["def aggregate_vectors(products):\n    product_vec = []\n    for i in products:\n        try:\n            product_vec.append(model[i])\n        except KeyError:\n            continue\n        \n    return np.mean(product_vec, axis=0)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"344cc9ae-3e20-45eb-9859-201898d290cb","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["If you can recall, we have already created a separate list of purchase sequences for validation purpose. Now let's make use of that."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6c4a7d8f-d694-4511-865b-b0834f0702a1","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["len(purchases_val[0])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ff20189d-163a-4944-a4d3-ebd41f7588ec","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["The length of the first list of products purchased by a user is 314. We will pass this products' sequence of the validation set to the function *aggregate_vectors*."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ccb8bf9b-dcac-4047-9111-33f3c0b2a30a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["aggregate_vectors(purchases_val[0]).shape"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aec02166-c4ee-4756-84fa-64e6dc01e1ea","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Well, the function has returned an array of 100 dimension. It means the function is working fine. Now we can use this result to get the most similar products. Let's do it."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c1643968-2089-4a0f-a13d-27a1f319fea7","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["similar_products(aggregate_vectors(purchases_val[0]))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"ac82d0ab-9533-482e-85e9-3e0b403ae1a5","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["As it turns out, our system has recommended 6 products based on the entire purchase history of a user. Moreover, if you want to get products suggestions based on the last few purchases only then also you can use the same set of functions.\n\nBelow I am giving only the last 10 products purchased as input."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"206b54dc-264f-4fef-b187-a1bb94903473","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["similar_products(aggregate_vectors(purchases_val[0][-10:]))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2cba547d-f0e9-4310-8c17-8ef7ced7a991","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"","errorSummary":"Command skipped","metadata":{},"errorTraceType":"ansi","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/plain":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["Feel free to play this code, try to get product recommendation for more sequences from the validation set"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b806ee1a-aaab-4944-bdd6-09b7b1b7b092","inputWidgets":{},"title":""}}}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.7.12","nbconvert_exporter":"python","file_extension":".py"},"application/vnd.databricks.v1+notebook":{"notebookName":"Generate Product Embeddings","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2166318613853809,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":3557846464623705}},"nbformat":4,"nbformat_minor":0}
